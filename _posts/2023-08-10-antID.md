---
layout: post
title:  "Using Machine Learning to Identify Individual Ants"
categories: [Machine Learning, Python, Computer Vision, OpenCV, PyTorch, C++]
image: assets/images/slower_bigger_ant.gif
featured: false
hidden: true
---

Machine Learning, Python, Computer Vision, OpenCV, PyTorch, C++

<div align="center"><iframe width="700" height="394" src="https://www.youtube.com/embed/8WXNRmXKI5E" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></div>


## Overview
The goal of this project was to create a system that could identify individual ants in a colony. Using
a machine vision camera equipped with a macro lens, I was able to collect ___insert number here___ images
of ___insert number here___ different harvester ants. These images were then used to train a machine learning
network to create a feature vector, or embedding, to describe each ant. By comparing embeddings of two
ants, a threshold could be used to determine if the ants are the same or different with a ___ give accuracy,
recall, precision, or whatever. 

### Why Ants?
The first reaction when I tell people about this project is typically something along the lines of "how
is this useful?" or "why would you want to do that?". The answer is that for most people, it's not
useful at all. However, for myrmecologists (ant scientists), it is very useful. Ants are very social 
insects that are commonly used to study social behavior and can be used to learn more about how swarms
of robots can be used to accomplish tasks. The current way of tracking individual ants in a colony is
an extremely tedious process that involves manually labeling each ant in a colony by painting different
patterns on them. Check out <a href="https://youtu.be/uAQ5IKVpysc">this video</a> to see exactly how tedious
this process can be. By creating a system that can automatically identify individual ants, we can save researchers a lot of time and effort.

## Project Setup and Hardware
To collect images of the ants, I used a Blackfly S camera from FLIR equipped with a macro lens. The 
camera was mounted on a microscope stand and placed above a 3D printed channel that the ants could
walk through. By using this setup, the ants were forced to walk in a straight line in the camera's
field of view. This entire setup was then placed inside of a light box to ensure consistent lighting.


<p align = "center"><img src="https://github.com/oubrejames/antID/assets/46512429/a5261545-e3ca-49aa-b72d-d54e64cbcd73" height="500"   width="350"/>  <img src="https://github.com/oubrejames/antID/assets/46512429/76fbd53c-77db-4546-b986-dc568ce16fc8" height="500"   width="350"/></p>

The image below shows the entire setup. There were two main living chambers for the ants. One for ants
that data had already been collected for and one for ants that data still needed to be imaged. There are
also multiple 3D printed gates to control the flow of ants from the living chambers to the data collection
area.

<p align = "center"><img src="https://github.com/oubrejames/antID/assets/46512429/cb99713f-b1f7-4a37-87c9-7e023232fd85" height="800"   width="700"/></p>
<p align = "center">Setup Overview</p>


## Data Collection

By using the setup described above, I was able to collect ___insert number here___ images of ___insert number here___ different ants. The traffic control gates were used to isolated one ant in the data collection area.
This allowed me to collect a video 

<p align = "center"><img src="https://github.com/oubrejames/antID/assets/46512429/d097f72f-aad7-4b84-8c3f-167528621f12" height="250"   width="500"/></p>
<p align = "center"><img src="https://github.com/oubrejames/antID/assets/46512429/9589a8a1-cd86-46d3-8b16-473048150340" height="250"   width="600"/></p>
<p align = "center">Ant Imaging Channel and Image</p>

To interact with the Blackfly camera and collect videos of the ants walking through the imaging channel, I 
had to first create a <a href="https://github.com/oubrejames/antID/tree/main/black_fly_tools">C++ library</a>
to interface with the camera. It allowed me to control all of the camera's settings and collect videos. I also created 
a scripts to semi-automatically collect videos of the ants.

When collecting videos, I would first let an ant walk into the data collection area and start recording. Once the ant walked under the camera enough, I would stop recording and have the ant walk to the separate living chamber. I would then repeat this process for each unfilmed ant. Videos were named sequentially as "ant_#.avi" so that I could keep track of which ant was in each video.

##  Methodology

<p align = "center"><img src="https://github.com/oubrejames/antID/assets/46512429/c10ccb0f-a427-44be-b271-7a9c534163ca" /></p>
<p align = "center">System Pipeline</p>

* talk about entire pipeline (might need to add voting and single pass detection)
* have a diagram of the pipeline
* very briefly overview the yolo steps
* go into detail about the embedding steps and triplet loss (mention/link facenet)
* have model architecture here 
* talk about how I chose threshold
* if you do voting explain how that increased the accuracy

##  Results

im here hello. 

* Give confusion matrix
* explain how I defined accuracy
* if you do voting say differences in accuracy and stuff between that and non-voting
* explain how I used thresholding and show graph with different thresholds

